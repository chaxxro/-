# 常见性能优化方法

## 栈内存偏见

堆是操作系统级别的概念，而栈是 cpu 级别的

`malloc` 堆区分配内存是很昂贵的，但栈内存的分配成本却很低

cpu 会提供两个寄存器 `sp` 和 `bp`，`bp` 和 `sp` 分别存取栈底和栈顶的地址。栈是从高地址向低地址增长的，所以减小 `sp` 代表增大栈空间，增大 `sp` 代表减少栈空间

对于一个函数，该函数需要多少栈空间是编译期间决定的，不会对运行时造成任何开销

x64 下 linux 默认给线程分配的栈是 8MB，如果在能保证不爆栈的情况下，务必优先在栈上分配内存空间，它是零开销的

## 函数内联

函数调用的性能开销：

1. 函数参数的传递需要写内存或寄存器

2. 调用函数的汇编可以简化为 `push return address` 和 `jump`，`jump` 是 cache 不友好的

3. 为保证 caller 上下文不被覆盖，还需要对 caller 的寄存器进行入栈保存

函数內联的本质就是代码复制拷贝，它会直接将 callee 的代码内容复制到 caller 的上下文中

內联函数好处：

1. 省略函数调用开销

2. 将函数的代码拷贝到 caller 上下文，从而编译器能做更多优化

內联后是在任何调用者处对函数代码做了拷贝，因此可能会导致生成的二进制更大

## 内存对齐

编译器倾向于将每个结构体成员的地址放在其大小的整数倍上，如 `uint64_t` 存取的地址就是 8*n，`uint32_t` 存取的地址是 4*n

非内存对齐可能会导致两次内存 IO

## 缓存伪共享 False Sharing

CPU缓存分为 3 层，即 L1、L2 以及 L3，其中 L1 离 CPU 最近，L3 离内存最近。每个 CPU 都有自己的缓存，介于 CPU 和内存之间

![01](常见性能优化方法.assets/01.png)

- L1 是距离 CPU 最近的缓存，其通常位于芯片中，容量为 8KB-64KB 之间。主要用于存储 CPU 核心最常访问的数据和指令，访问速度与 CPU 相当，大概消耗 1 到 3 个时钟周期

- L2 位于 L1 和 L3 之间，拥有更多的缓存，一般为 64KB-4MB 之间。如果 CPU 对数据进行修改，其首先会更新 L1，但是这些更新也会反应在 L2 中
- L3 位于 L2 之后，更接近于内存，通常位于主板上，用以保存各个 CPU 核的公共数据。如果 CPU 修改了某些数据，这些更改也会出现在 L3 缓存中。L3 缓存使用一致性协议，因此所有核心都可以一致地访问缓存中的任何数据

当 CPU 从内存或缓存读取数据时，它不会读取单个字节，而是读取一个字节块，通常为 64 个字节。我们将这个字节块称为缓存行

缓存抖动（Cache Thrashing），就是缓存来回频繁失效，导致 CPU 总是得去内存里重新拿数据，缓存几乎没起到加速作用，反而拖慢了性能

如果 CPU 需要访问已从上一个缓存行中提取的变量，则读取速度会更快。然而，由于 CPU 会根据缓存行维护一致性，因此如果缓存行中的任何一个字节发生更改，所有缓存行都会失效，并且集群中的所有 CPU 都会受到影响。如果不同的 CPU 需要处理同一缓存行上共享的变量，则会产生缓存抖动，并导致错误共享

## 无分支编程

在冯诺依曼架构计算机下，指令和数据都存在内存中。对于一条指令的执行肯定是分很多过程的，以最经典的五级流水线为例，一条指令分为如下阶段：

1. 取址(IF)：从内存中读取出指令

2. 译码(ID)：咱们得先知道取的是什么指令

3. 执行(EX)

4. 访存(MEM)：指令总有操作数嘛，访存获取它们或者将计算结果写入到内存

5. 写回(WB)：将执行结果写入到目标寄存器

每个阶段可以简单理解为有专门的一个 CPU 部件处理

为了更好的压榨每个部件的，CPU 引入了流水化技术，核心原理就是上一条指令立马发射就紧跟着发射下一条待执行的指令

遇到条件判断时 CPU 会面临一个问题，往后具有两个分支，流水线会停下来等到有结果了再继续执行

分支预测是基于分支的历史信息，分支的条件越具有规律性，那么 CPU 对分支预测的越准确